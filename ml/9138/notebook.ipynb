{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://www.mql5.com/en/articles/9138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3.9 -m pip install --upgrade pip\n",
    "%pip install --upgrade catboost sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from features\n",
      "Iteration: 0, R^2: 0.7869834145754087\n",
      "Iteration: 1, R^2: 0.8661674335313\n",
      "Iteration: 2, R^2: 0.9059378545190929\n",
      "Iteration: 3, R^2: 0.9072496396633793\n",
      "Iteration: 4, R^2: 0.9161690218162651\n",
      "Iteration: 5, R^2: 0.9131832317609125\n",
      "Iteration: 6, R^2: 0.9214444390784755\n",
      "Iteration: 7, R^2: 0.9107290663772053\n",
      "Iteration: 8, R^2: 0.89066558085443\n",
      "Iteration: 9, R^2: 0.9141973608498362\n",
      "Iteration: 10, R^2: 0.8916404576917382\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb Zelle 3\u001b[0m in \u001b[0;36m<cell line: 338>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=336'>337</a>\u001b[0m BAD_SAMPLES_BOOK \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDatetimeIndex([])\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=337'>338</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m25\u001b[39m):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=338'>339</a>\u001b[0m     res\u001b[39m.\u001b[39mappend(brute_force(pr[pr\u001b[39m.\u001b[39;49mcolumns[\u001b[39m1\u001b[39;49m:]], bad_samples_fraction\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=340'>341</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mIteration: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, R^2: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(i, res[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=341'>342</a>\u001b[0m     pr \u001b[39m=\u001b[39m res[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m3\u001b[39m] \n",
      "\u001b[1;32m/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb Zelle 3\u001b[0m in \u001b[0;36mbrute_force\u001b[0;34m(dataset, bad_samples_fraction)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=189'>190</a>\u001b[0m pr2[\u001b[39m'\u001b[39m\u001b[39mmeta_labels\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m meta_labels\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=191'>192</a>\u001b[0m \u001b[39m# resample labels based on meta labels\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=192'>193</a>\u001b[0m pr2 \u001b[39m=\u001b[39m labelling_relabeling(pr2, relabeling\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=193'>194</a>\u001b[0m pr2[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pr2[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=194'>195</a>\u001b[0m pr2[\u001b[39m'\u001b[39m\u001b[39mmeta_labels\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pr2[\u001b[39m'\u001b[39m\u001b[39mmeta_labels\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n",
      "\u001b[1;32m/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb Zelle 3\u001b[0m in \u001b[0;36mlabelling_relabeling\u001b[0;34m(dataset, min, max, relabeling)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m future_pr \u001b[39m=\u001b[39m dataset[\u001b[39m'\u001b[39m\u001b[39mclose\u001b[39m\u001b[39m'\u001b[39m][i \u001b[39m+\u001b[39m rand]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mif\u001b[39;00m relabeling:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     m_labels  \u001b[39m=\u001b[39m dataset[\u001b[39m'\u001b[39;49m\u001b[39mmeta_labels\u001b[39;49m\u001b[39m'\u001b[39;49m][i:rand\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mif\u001b[39;00m relabeling \u001b[39mand\u001b[39;00m \u001b[39m0.0\u001b[39m \u001b[39min\u001b[39;00m m_labels:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     labels\u001b[39m.\u001b[39mappend(\u001b[39m2.0\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/series.py:979\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m    977\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m--> 979\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39;49mis_bool_indexer(key):\n\u001b[1;32m    980\u001b[0m     key \u001b[39m=\u001b[39m check_bool_indexer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, key)\n\u001b[1;32m    981\u001b[0m     key \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(key, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/common.py:134\u001b[0m, in \u001b[0;36mis_bool_indexer\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_bool_indexer\u001b[39m(key: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m    106\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[39m    Check whether `key` is a valid boolean indexer.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39m        and convert to an ndarray.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, (ABCSeries, np\u001b[39m.\u001b[39mndarray, ABCIndex)) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m--> 134\u001b[0m         is_array_like(key) \u001b[39mand\u001b[39;00m is_extension_array_dtype(key\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    135\u001b[0m     ):\n\u001b[1;32m    136\u001b[0m         \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mobject_:\n\u001b[1;32m    137\u001b[0m             key \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(key)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/dtypes/inference.py:213\u001b[0m, in \u001b[0;36mis_array_like\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_array_like\u001b[39m(obj) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m    185\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[39m    Check if the object is array-like.\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39m    False\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m     \u001b[39mreturn\u001b[39;00m is_list_like(obj) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from cmath import cos\n",
    "import catboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "\n",
    "from pea.features import update_features, get_historic_prices, SYMBOL, get_X\n",
    "\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "MARKUP = 0.00002\n",
    "START_DATE = datetime(2020, 1, 1)\n",
    "TSTART_DATE = datetime(2018, 1, 1)\n",
    "STOP_DATE = datetime(2021, 1, 1)\n",
    "BAD_SAMPLES_BOOK = pd.DatetimeIndex([])\n",
    "\n",
    "def labelling_relabeling(dataset, min=15, max=35, relabeling=False):\n",
    "    labels = []\n",
    "    for i in range(dataset.shape[0]-max):\n",
    "        rand = random.randint(min, max)\n",
    "        curr_pr = dataset['close'][i]\n",
    "        future_pr = dataset['close'][i + rand]\n",
    "\n",
    "        if relabeling:\n",
    "            m_labels  = dataset['meta_labels'][i:rand+1].values\n",
    "        \n",
    "        if relabeling and 0.0 in m_labels:\n",
    "            labels.append(2.0)\n",
    "        else:\n",
    "            if future_pr + MARKUP < curr_pr:\n",
    "                labels.append(1.0)\n",
    "            elif future_pr - MARKUP > curr_pr:\n",
    "                labels.append(0.0)\n",
    "            else:\n",
    "                labels.append(2.0)\n",
    "        \n",
    "    dataset = dataset.iloc[:len(labels)].copy()\n",
    "    dataset['labels'] = labels\n",
    "    dataset = dataset.dropna()\n",
    "    dataset = dataset.drop(\n",
    "        dataset[dataset.labels == 2].index)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def tester(dataset: pd.DataFrame, markup=0.0, use_meta=False, plot=False):\n",
    "    last_deal = int(2)\n",
    "    last_price = 0.0\n",
    "    report = [0.0]\n",
    "    meta_labels = dataset['labels'].copy()\n",
    "\n",
    "    for i in range(dataset.shape[0]):\n",
    "        pred = dataset['labels'][i]\n",
    "        meta_labels[i] = np.nan\n",
    "        if use_meta:\n",
    "            pred_meta = dataset['meta_labels'][i] # 1 = allow trades\n",
    "\n",
    "        if last_deal == 2 and ((use_meta and pred_meta==1) or not use_meta):\n",
    "            last_price = dataset['close'][i]\n",
    "            last_deal = 0 if pred <= 0.5 else 1\n",
    "            continue\n",
    "\n",
    "        if last_deal == 0 and pred > 0.5 and ((use_meta and pred_meta==1) or not use_meta):\n",
    "            last_deal = 2\n",
    "            report.append(report[-1] - markup +\n",
    "                          (dataset['close'][i] - last_price))\n",
    "            if report[-1] > report[-2]:\n",
    "                meta_labels[i] = 1\n",
    "            else:\n",
    "                meta_labels[i] = 0\n",
    "            continue\n",
    "\n",
    "        if last_deal == 1 and pred < 0.5 and ((use_meta and pred_meta==1) or not use_meta):\n",
    "            last_deal = 2\n",
    "            report.append(report[-1] - markup +\n",
    "                          (last_price - dataset['close'][i]))\n",
    "            if report[-1] > report[-2]:\n",
    "                meta_labels[i] = 1\n",
    "            else:\n",
    "                meta_labels[i] = 0\n",
    "\n",
    "    y = np.array(report).reshape(-1, 1)\n",
    "    X = np.arange(len(report)).reshape(-1, 1)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X, y)\n",
    "\n",
    "    l = lr.coef_\n",
    "    if l >= 0:\n",
    "        l = 1\n",
    "    else:\n",
    "        l = -1\n",
    "\n",
    "    if(plot):\n",
    "        plt.plot(report)\n",
    "        plt.plot(lr.predict(X))\n",
    "        plt.title(\"Strategy performance R^2 \" + str(format(lr.score(X, y) * l,\".2f\")))\n",
    "        plt.xlabel(\"the number of trades\")\n",
    "        plt.ylabel(\"cumulative profit in pips\")\n",
    "        plt.show()\n",
    "\n",
    "    return lr.score(X, y) * l, meta_labels.fillna(method='backfill')\n",
    "\n",
    "def brute_force(dataset, bad_samples_fraction=0.5):\n",
    "    # features for model\\meta models. We learn main model only on filtered labels \n",
    "    X = dataset[dataset['meta_labels']==1]\n",
    "    X = dataset[dataset.columns[:-2]]\n",
    "    X = X[X.index >= START_DATE]\n",
    "    X = X[X.index <= STOP_DATE]\n",
    "\n",
    "    X_meta = dataset[dataset.columns[:-2]]\n",
    "    X_meta = X_meta[X_meta.index >= TSTART_DATE]\n",
    "    X_meta = X_meta[X_meta.index <= STOP_DATE]\n",
    "\n",
    "    # labels for model\\meta models\n",
    "    y = dataset[dataset['meta_labels']==1]\n",
    "    y = dataset[dataset.columns[-2]]\n",
    "    y = y[y.index >= START_DATE]\n",
    "    y = y[y.index <= STOP_DATE]\n",
    "\n",
    "    y_meta = dataset[dataset.columns[-1]]\n",
    "    y_meta = y_meta[y_meta.index >= TSTART_DATE]\n",
    "    y_meta = y_meta[y_meta.index <= STOP_DATE]\n",
    "\n",
    "    # train\\test split\n",
    "    train_X, test_X, train_y, test_y = train_test_split(\n",
    "        X, y, train_size=0.5, test_size=0.5, shuffle=True)\n",
    "\n",
    "    # learn main model with train and validation subsets\n",
    "    model = CatBoostClassifier(iterations=1000,\n",
    "                               depth=6,\n",
    "                               learning_rate=0.1,\n",
    "                               custom_loss=['Accuracy'],\n",
    "                               eval_metric='Accuracy',\n",
    "                               verbose=False,\n",
    "                               use_best_model=True,\n",
    "                               task_type='CPU')\n",
    "\n",
    "    model.fit(train_X, train_y, eval_set=(test_X, test_y),\n",
    "              early_stopping_rounds=50, plot=False)\n",
    "\n",
    "    # train\\test split\n",
    "    train_X, test_X, train_y, test_y = train_test_split(\n",
    "        X_meta, y_meta, train_size=0.5, test_size=0.5, shuffle=True)\n",
    "\n",
    "    # learn meta model with train and validation subsets\n",
    "    meta_model = CatBoostClassifier(iterations=1000,\n",
    "                                    depth=6,\n",
    "                                    learning_rate=0.1,\n",
    "                                    custom_loss=['Accuracy'],\n",
    "                                    eval_metric='Accuracy',\n",
    "                                    verbose=False,\n",
    "                                    use_best_model=True,\n",
    "                                    task_type='CPU')\n",
    "\n",
    "    meta_model.fit(train_X, train_y, eval_set=(test_X, test_y),\n",
    "              early_stopping_rounds=50, plot=False)\n",
    "\n",
    "    # predict on new data (validation plus learning)\n",
    "    pr_tst = get_historic_prices()\n",
    "    X = pr_tst[pr_tst.columns[1:]]\n",
    "    X.columns = [''] * len(X.columns)\n",
    "    X_meta = X.copy()\n",
    "\n",
    "    # predict the learned models (base and meta)\n",
    "    p = model.predict_proba(X)\n",
    "    p_meta = meta_model.predict_proba(X_meta)\n",
    "\n",
    "    p2 = [x[0] < 0.5 for x in p]\n",
    "    p2_meta = [x[0] < 0.5 for x in p_meta]\n",
    "    pr2 = pr_tst.iloc[:len(p2)].copy()\n",
    "    pr2['labels'] = p2\n",
    "    pr2['meta_labels'] = p2_meta\n",
    "    pr2['labels'] = pr2['labels'].astype(float)\n",
    "    pr2['meta_labels'] = pr2['meta_labels'].astype(float)\n",
    "    full_pr = pr2.copy()\n",
    "    pr2 = pr2[pr2.index >= TSTART_DATE]\n",
    "    pr2 = pr2[pr2.index <= STOP_DATE]\n",
    "\n",
    "    # add bad samples of this iteratin (bad meta labels)\n",
    "    global BAD_SAMPLES_BOOK\n",
    "    BAD_SAMPLES_BOOK = BAD_SAMPLES_BOOK.append(pr2[pr2['meta_labels']==0.0].index)\n",
    "    \n",
    "    # test models and resample meta labels\n",
    "    R2, meta_labels = tester(pr2, MARKUP, use_meta=True, plot=False)\n",
    "    pr2['meta_labels'] = meta_labels\n",
    "\n",
    "    # resample labels based on meta labels\n",
    "    pr2 = labelling_relabeling(pr2, relabeling=True)\n",
    "    pr2['labels'] = pr2['labels'].astype(float)\n",
    "    pr2['meta_labels'] = pr2['meta_labels'].astype(float)\n",
    "\n",
    "    # mark bad labels from bad_samples_book\n",
    "    if BAD_SAMPLES_BOOK.value_counts().max() > 1:\n",
    "        to_mark = BAD_SAMPLES_BOOK.value_counts()\n",
    "        mean = to_mark.mean()\n",
    "        marked_idx = to_mark[to_mark > mean*bad_samples_fraction].index\n",
    "        pr2.loc[pr2.index.isin(marked_idx), 'meta_labels'] = 0.0\n",
    "    else:\n",
    "        pr2.loc[pr2.index.isin(BAD_SAMPLES_BOOK), 'meta_labels'] = 0.0\n",
    "\n",
    "    R2, _ = tester(full_pr, MARKUP, use_meta=True, plot=False)\n",
    "\n",
    "    return [R2, model, meta_model, pr2]\n",
    "\n",
    "def test_model(result: list):\n",
    "    pr_tst = get_historic_prices()\n",
    "    # print('pr_tst')\n",
    "    # print(pr_tst)\n",
    "    # print(pr_tst.describe())\n",
    "    X = get_X(pr_tst)\n",
    "    # print('X')\n",
    "    # print(X)\n",
    "    # print(X.describe())\n",
    "    # X.columns = [''] * len(X.columns)\n",
    "    X_meta = X.copy()\n",
    "    # print('X_meta')\n",
    "    # print(X_meta)\n",
    "    # print(X_meta.describe())\n",
    "\n",
    "    # test the learned model\n",
    "    p = result[1].predict_proba(X)\n",
    "    p_meta = result[2].predict_proba(X_meta)\n",
    "    p2 = [x[0] < 0.5 for x in p]\n",
    "    p2_meta = [x[0] < 0.5 for x in p_meta]\n",
    "    pr2 = pr_tst.iloc[:len(p2)].copy()\n",
    "    pr2['labels'] = p2\n",
    "    pr2['labels'] = pr2['labels'].astype(float)\n",
    "    pr2['meta_labels'] = p2_meta  \n",
    "    pr2['meta_labels'] = pr2['meta_labels'].astype(float)\n",
    "    R2, meta_labels = tester(pr2, MARKUP, use_meta=True, plot=True)\n",
    "\n",
    "def export_model_to_MQL_code(model, model_number):\n",
    "    model[1].save_model('catmodel.h',\n",
    "                     format=\"cpp\",\n",
    "                     export_parameters=None,\n",
    "                     pool=None)\n",
    "    model[2].save_model('meta_catmodel.h',\n",
    "                     format=\"cpp\",\n",
    "                     export_parameters=None,\n",
    "                     pool=None)\n",
    "    # add variables\n",
    "    code = '#include <Math\\Stat\\Math.mqh>'\n",
    "    code += '\\n'\n",
    "    code += 'int MAs' + model_number + '[' + str(len(MA_PERIODS)) + \\\n",
    "        '] = {' + ','.join(map(str, MA_PERIODS)) + '};'\n",
    "    code += '\\n'\n",
    "\n",
    "    # get features\n",
    "    code += 'void fill_arays' + model_number + '( double &features[]) {\\n'\n",
    "    code += '   double pr[], ret[];\\n'\n",
    "    code += '   ArrayResize(ret, 1);\\n'\n",
    "    code += '   for(int i=ArraySize(MAs' + model_number + ')-1; i>=0; i--) {\\n'\n",
    "    code += '       CopyClose(NULL,PERIOD_CURRENT,1,MAs' + model_number + '[i],pr);\\n'\n",
    "    code += '       double mean = MathMean(pr);\\n'\n",
    "    code += '       double std = MathStandardDeviation(pr);\\n'\n",
    "    code += '       ret[0] = pr[MAs' + model_number + '[i]-1] - mean;\\n'\n",
    "    code += '       ArrayInsert(features, ret, ArraySize(features), 0, WHOLE_ARRAY); }\\n'\n",
    "    code += '   ArraySetAsSeries(features, true);\\n'\n",
    "    code += '}\\n\\n'\n",
    "\n",
    "    # add CatBosst base model\n",
    "    code += 'double catboost_model' + model_number + '(const double &features[]) { \\n'\n",
    "    code += '    '\n",
    "    with open('catmodel.h', 'r') as file:\n",
    "        data = file.read()\n",
    "        code += data[data.find(\"unsigned int TreeDepth\")\n",
    "                               :data.find(\"double Scale = 1;\")]\n",
    "    code += '\\n\\n'\n",
    "    code += 'return ' + \\\n",
    "        'ApplyCatboostModel' + model_number + '(features, TreeDepth, TreeSplits , BorderCounts, Borders, LeafValues); } \\n\\n'\n",
    "\n",
    "    # add CatBosst meta model\n",
    "    code += 'double catboost_meta_model' + model_number + '(const double &features[]) { \\n'\n",
    "    code += '    '\n",
    "    with open('meta_catmodel.h', 'r') as file:\n",
    "        data = file.read()\n",
    "        code += data[data.find(\"unsigned int TreeDepth\")\n",
    "                               :data.find(\"double Scale = 1;\")]\n",
    "    code += '\\n\\n'\n",
    "    code += 'return ' + \\\n",
    "        'ApplyCatboostModel' + model_number + '(features, TreeDepth, TreeSplits , BorderCounts, Borders, LeafValues); } \\n\\n'\n",
    "\n",
    "    code += 'double ApplyCatboostModel' + model_number + '(const double &features[],uint &TreeDepth_[],uint &TreeSplits_[],uint &BorderCounts_[],float &Borders_[],double &LeafValues_[]) {\\n\\\n",
    "    uint FloatFeatureCount=ArrayRange(BorderCounts_,0);\\n\\\n",
    "    uint BinaryFeatureCount=ArrayRange(Borders_,0);\\n\\\n",
    "    uint TreeCount=ArrayRange(TreeDepth_,0);\\n\\\n",
    "    bool     binaryFeatures[];\\n\\\n",
    "    ArrayResize(binaryFeatures,BinaryFeatureCount);\\n\\\n",
    "    uint binFeatureIndex=0;\\n\\\n",
    "    for(uint i=0; i<FloatFeatureCount; i++) {\\n\\\n",
    "       for(uint j=0; j<BorderCounts_[i]; j++) {\\n\\\n",
    "          binaryFeatures[binFeatureIndex]=features[i]>Borders_[binFeatureIndex];\\n\\\n",
    "          binFeatureIndex++;\\n\\\n",
    "       }\\n\\\n",
    "    }\\n\\\n",
    "    double result=0.0;\\n\\\n",
    "    uint treeSplitsPtr=0;\\n\\\n",
    "    uint leafValuesForCurrentTreePtr=0;\\n\\\n",
    "    for(uint treeId=0; treeId<TreeCount; treeId++) {\\n\\\n",
    "       uint currentTreeDepth=TreeDepth_[treeId];\\n\\\n",
    "       uint index=0;\\n\\\n",
    "       for(uint depth=0; depth<currentTreeDepth; depth++) {\\n\\\n",
    "          index|=(binaryFeatures[TreeSplits_[treeSplitsPtr+depth]]<<depth);\\n\\\n",
    "       }\\n\\\n",
    "       result+=LeafValues_[leafValuesForCurrentTreePtr+index];\\n\\\n",
    "       treeSplitsPtr+=currentTreeDepth;\\n\\\n",
    "       leafValuesForCurrentTreePtr+=(1<<currentTreeDepth);\\n\\\n",
    "    }\\n\\\n",
    "    return 1.0/(1.0+MathPow(M_E,-result));\\n\\\n",
    "    }\\n\\n'\n",
    "\n",
    "\n",
    "\n",
    "    # file = open('/Users/dmitrievsky/Desktop/py files/mql models/' + str(SYMBOL) + 'cat_model_META_NEW' + model_number + '.mqh', \"w\")\n",
    "    file = open(str(SYMBOL) + 'cat_model_META_NEW' + model_number + '.mqh', \"w\")\n",
    "    file.write(code)\n",
    "\n",
    "    file.close()\n",
    "    print('The file ' + 'cat_model' + '.mqh ' + 'has been written to disc')\n",
    "\n",
    "\n",
    "# make dataset\n",
    "pr = get_historic_prices()\n",
    "pr = labelling_relabeling(pr, relabeling=False)\n",
    "a, b = tester(pr, MARKUP, use_meta=False, plot=False)\n",
    "pr['meta_labels'] = b\n",
    "pr = pr.dropna()\n",
    "pr = labelling_relabeling(pr, relabeling=True)\n",
    "\n",
    "# iterative learning\n",
    "res = []\n",
    "BAD_SAMPLES_BOOK = pd.DatetimeIndex([])\n",
    "# for i in range(25):\n",
    "for i in range(6):\n",
    "    res.append(brute_force(pr[pr.columns[1:]], bad_samples_fraction=0.5))\n",
    "\n",
    "    print('Iteration: {}, R^2: {}'.format(i, res[-1][0]))\n",
    "    pr = res[-1][3] \n",
    "\n",
    "# export best model to mql\n",
    "# export_model_to_MQL_code(res[-1], str(1))\n",
    "\n",
    "# test best model\n",
    "res.sort()\n",
    "best_model=res[-1]\n",
    "p = test_model(best_model)\n",
    "\n",
    "# save model\n",
    "best_model[1].save_model(\"catmodel.cbm\")\n",
    "best_model[2].save_model(\"meta_catmodel.cbm\")\n",
    "\n",
    "# export best model to mql\n",
    "# export_model_to_MQL_code(res[-1], str(1))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
