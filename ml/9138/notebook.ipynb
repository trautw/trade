{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://www.mql5.com/en/articles/9138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3.9 -m pip install --upgrade pip\n",
    "%pip install --upgrade catboost sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, R^2: 0.12402754163195018\n",
      "Iteration: 1, R^2: 0.615971943945263\n",
      "Iteration: 2, R^2: 0.7692162605312209\n",
      "Iteration: 3, R^2: 0.7947555455181532\n",
      "Iteration: 4, R^2: 0.7752824345780354\n",
      "Iteration: 5, R^2: 0.9167331002697839\n",
      "Iteration: 6, R^2: 0.8328138581670761\n",
      "Iteration: 7, R^2: 0.7856264835270467\n",
      "Iteration: 8, R^2: 0.9588902854232861\n",
      "Iteration: 9, R^2: 0.9068349523914215\n",
      "Iteration: 10, R^2: 0.8692725082374982\n",
      "Iteration: 11, R^2: 0.8594213965409452\n",
      "Iteration: 12, R^2: 0.9475889978882847\n",
      "Iteration: 13, R^2: 0.9372468058375784\n",
      "Iteration: 14, R^2: 0.8825721681454164\n",
      "Iteration: 15, R^2: 0.9813493714711394\n",
      "Iteration: 16, R^2: 0.9816942458296429\n",
      "Iteration: 17, R^2: 0.9688294697067807\n",
      "Iteration: 18, R^2: 0.9406881688173279\n",
      "Iteration: 19, R^2: 0.9765757653277983\n",
      "Iteration: 20, R^2: 0.9214189201204657\n",
      "Iteration: 21, R^2: 0.9196311020495354\n",
      "Iteration: 22, R^2: 0.9490165016197478\n",
      "Iteration: 23, R^2: 0.9741250785987872\n",
      "Iteration: 24, R^2: 0.9436861164650377\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "Input data must have at least one feature",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb Zelle 3\u001b[0m in \u001b[0;36m<cell line: 352>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=349'>350</a>\u001b[0m res\u001b[39m.\u001b[39msort()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=350'>351</a>\u001b[0m best_model\u001b[39m=\u001b[39mres[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=351'>352</a>\u001b[0m p \u001b[39m=\u001b[39m test_model(best_model)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=353'>354</a>\u001b[0m \u001b[39m# save model\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=354'>355</a>\u001b[0m best_model[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msave_model(\u001b[39m\"\u001b[39m\u001b[39mcatmodel.cbm\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb Zelle 3\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(result)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=220'>221</a>\u001b[0m X_meta \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=221'>222</a>\u001b[0m \u001b[39m# print('X_meta')\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=222'>223</a>\u001b[0m \u001b[39m# print(X_meta)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=223'>224</a>\u001b[0m \u001b[39m# print(X_meta.describe())\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=224'>225</a>\u001b[0m \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=225'>226</a>\u001b[0m \u001b[39m# test the learned model\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=226'>227</a>\u001b[0m p \u001b[39m=\u001b[39m result[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=227'>228</a>\u001b[0m p_meta \u001b[39m=\u001b[39m result[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mpredict_proba(X_meta)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/c.trautwein/Projekte/trade/ml/9138/notebook.ipynb#W2sZmlsZQ%3D%3D?line=228'>229</a>\u001b[0m p2 \u001b[39m=\u001b[39m [x[\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m p]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/catboost/core.py:5101\u001b[0m, in \u001b[0;36mCatBoostClassifier.predict_proba\u001b[0;34m(self, X, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[1;32m   5065\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_proba\u001b[39m(\u001b[39mself\u001b[39m, X, ntree_start\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, ntree_end\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, thread_count\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, task_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCPU\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   5066\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5067\u001b[0m \u001b[39m    Predict class probability with X.\u001b[39;00m\n\u001b[1;32m   5068\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5099\u001b[0m \u001b[39m            with probability for every class for each object.\u001b[39;00m\n\u001b[1;32m   5100\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(X, \u001b[39m'\u001b[39;49m\u001b[39mProbability\u001b[39;49m\u001b[39m'\u001b[39;49m, ntree_start, ntree_end, thread_count, verbose, \u001b[39m'\u001b[39;49m\u001b[39mpredict_proba\u001b[39;49m\u001b[39m'\u001b[39;49m, task_type)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/catboost/core.py:2458\u001b[0m, in \u001b[0;36mCatBoost._predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[0m\n\u001b[1;32m   2456\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2457\u001b[0m     verbose \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 2458\u001b[0m data, data_is_single_object \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_predict_input_data(data, parent_method_name, thread_count)\n\u001b[1;32m   2459\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_prediction_type(prediction_type)\n\u001b[1;32m   2461\u001b[0m predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/catboost/core.py:2438\u001b[0m, in \u001b[0;36mCatBoost._process_predict_input_data\u001b[0;34m(self, data, parent_method_name, thread_count, label)\u001b[0m\n\u001b[1;32m   2436\u001b[0m is_single_object \u001b[39m=\u001b[39m _is_data_single_object(data)\n\u001b[1;32m   2437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Pool):\n\u001b[0;32m-> 2438\u001b[0m     data \u001b[39m=\u001b[39m Pool(\n\u001b[1;32m   2439\u001b[0m         data\u001b[39m=\u001b[39;49m[data] \u001b[39mif\u001b[39;49;00m is_single_object \u001b[39melse\u001b[39;49;00m data,\n\u001b[1;32m   2440\u001b[0m         label\u001b[39m=\u001b[39;49mlabel,\n\u001b[1;32m   2441\u001b[0m         cat_features\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_cat_feature_indices() \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data, FeaturesData) \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2442\u001b[0m         text_features\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_text_feature_indices() \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data, FeaturesData) \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2443\u001b[0m         embedding_features\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_embedding_feature_indices() \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data, FeaturesData) \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2444\u001b[0m         thread_count\u001b[39m=\u001b[39;49mthread_count\n\u001b[1;32m   2445\u001b[0m     )\n\u001b[1;32m   2446\u001b[0m \u001b[39mreturn\u001b[39;00m data, is_single_object\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/catboost/core.py:705\u001b[0m, in \u001b[0;36mPool.__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_data_type(data)\n\u001b[0;32m--> 705\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_data_empty(data)\n\u001b[1;32m    706\u001b[0m     \u001b[39mif\u001b[39;00m pairs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(data, PATH_TYPES) \u001b[39m!=\u001b[39m \u001b[39misinstance\u001b[39m(pairs, PATH_TYPES):\n\u001b[1;32m    707\u001b[0m         \u001b[39mraise\u001b[39;00m CatBoostError(\u001b[39m\"\u001b[39m\u001b[39mdata and pairs parameters should be the same types.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/catboost/core.py:885\u001b[0m, in \u001b[0;36mPool._check_data_empty\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    883\u001b[0m     \u001b[39mraise\u001b[39;00m CatBoostError(\u001b[39m\"\u001b[39m\u001b[39mInput data has invalid shape: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. Must be 2 dimensional\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(data_shape))\n\u001b[1;32m    884\u001b[0m \u001b[39mif\u001b[39;00m data_shape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 885\u001b[0m     \u001b[39mraise\u001b[39;00m CatBoostError(\u001b[39m\"\u001b[39m\u001b[39mInput data must have at least one feature\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mCatBoostError\u001b[0m: Input data must have at least one feature"
     ]
    }
   ],
   "source": [
    "from cmath import cos\n",
    "import catboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "\n",
    "from pea.features import get_features, get_historic_prices, SYMBOL, get_X\n",
    "\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "MARKUP = 0.00002\n",
    "START_DATE = datetime(2021, 1, 1)\n",
    "TSTART_DATE = datetime(2018, 1, 1)\n",
    "STOP_DATE = datetime(2022, 1, 1)\n",
    "BAD_SAMPLES_BOOK = pd.DatetimeIndex([])\n",
    "\n",
    "def labelling_relabeling(dataset, min=15, max=35, relabeling=False):\n",
    "    labels = []\n",
    "    for i in range(dataset.shape[0]-max):\n",
    "        rand = random.randint(min, max)\n",
    "        curr_pr = dataset['close'][i]\n",
    "        future_pr = dataset['close'][i + rand]\n",
    "\n",
    "        if relabeling:\n",
    "            m_labels  = dataset['meta_labels'][i:rand+1].values\n",
    "        \n",
    "        if relabeling and 0.0 in m_labels:\n",
    "            labels.append(2.0)\n",
    "        else:\n",
    "            if future_pr + MARKUP < curr_pr:\n",
    "                labels.append(1.0)\n",
    "            elif future_pr - MARKUP > curr_pr:\n",
    "                labels.append(0.0)\n",
    "            else:\n",
    "                labels.append(2.0)\n",
    "        \n",
    "    dataset = dataset.iloc[:len(labels)].copy()\n",
    "    dataset['labels'] = labels\n",
    "    dataset = dataset.dropna()\n",
    "    dataset = dataset.drop(\n",
    "        dataset[dataset.labels == 2].index)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def tester(dataset: pd.DataFrame, markup=0.0, use_meta=False, plot=False):\n",
    "    last_deal = int(2)\n",
    "    last_price = 0.0\n",
    "    report = [0.0]\n",
    "    meta_labels = dataset['labels'].copy()\n",
    "\n",
    "    for i in range(dataset.shape[0]):\n",
    "        pred = dataset['labels'][i]\n",
    "        meta_labels[i] = np.nan\n",
    "        if use_meta:\n",
    "            pred_meta = dataset['meta_labels'][i] # 1 = allow trades\n",
    "\n",
    "        if last_deal == 2 and ((use_meta and pred_meta==1) or not use_meta):\n",
    "            last_price = dataset['close'][i]\n",
    "            last_deal = 0 if pred <= 0.5 else 1\n",
    "            continue\n",
    "\n",
    "        if last_deal == 0 and pred > 0.5 and ((use_meta and pred_meta==1) or not use_meta):\n",
    "            last_deal = 2\n",
    "            report.append(report[-1] - markup +\n",
    "                          (dataset['close'][i] - last_price))\n",
    "            if report[-1] > report[-2]:\n",
    "                meta_labels[i] = 1\n",
    "            else:\n",
    "                meta_labels[i] = 0\n",
    "            continue\n",
    "\n",
    "        if last_deal == 1 and pred < 0.5 and ((use_meta and pred_meta==1) or not use_meta):\n",
    "            last_deal = 2\n",
    "            report.append(report[-1] - markup +\n",
    "                          (last_price - dataset['close'][i]))\n",
    "            if report[-1] > report[-2]:\n",
    "                meta_labels[i] = 1\n",
    "            else:\n",
    "                meta_labels[i] = 0\n",
    "\n",
    "    y = np.array(report).reshape(-1, 1)\n",
    "    X = np.arange(len(report)).reshape(-1, 1)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X, y)\n",
    "\n",
    "    l = lr.coef_\n",
    "    if l >= 0:\n",
    "        l = 1\n",
    "    else:\n",
    "        l = -1\n",
    "\n",
    "    if(plot):\n",
    "        plt.plot(report)\n",
    "        plt.plot(lr.predict(X))\n",
    "        plt.title(\"Strategy performance R^2 \" + str(format(lr.score(X, y) * l,\".2f\")))\n",
    "        plt.xlabel(\"the number of trades\")\n",
    "        plt.ylabel(\"cumulative profit in pips\")\n",
    "        plt.show()\n",
    "\n",
    "    return lr.score(X, y) * l, meta_labels.fillna(method='backfill')\n",
    "\n",
    "def brute_force(dataset, bad_samples_fraction=0.5):\n",
    "    # features for model\\meta models. We learn main model only on filtered labels \n",
    "    X = dataset[dataset['meta_labels']==1]\n",
    "    X = dataset[dataset.columns[:-2]]\n",
    "    X = X[X.index >= START_DATE]\n",
    "    X = X[X.index <= STOP_DATE]\n",
    "\n",
    "    X_meta = dataset[dataset.columns[:-2]]\n",
    "    X_meta = X_meta[X_meta.index >= TSTART_DATE]\n",
    "    X_meta = X_meta[X_meta.index <= STOP_DATE]\n",
    "\n",
    "    # labels for model\\meta models\n",
    "    y = dataset[dataset['meta_labels']==1]\n",
    "    y = dataset[dataset.columns[-2]]\n",
    "    y = y[y.index >= START_DATE]\n",
    "    y = y[y.index <= STOP_DATE]\n",
    "\n",
    "    y_meta = dataset[dataset.columns[-1]]\n",
    "    y_meta = y_meta[y_meta.index >= TSTART_DATE]\n",
    "    y_meta = y_meta[y_meta.index <= STOP_DATE]\n",
    "\n",
    "    # train\\test split\n",
    "    train_X, test_X, train_y, test_y = train_test_split(\n",
    "        X, y, train_size=0.5, test_size=0.5, shuffle=True)\n",
    "\n",
    "    # learn main model with train and validation subsets\n",
    "    model = CatBoostClassifier(iterations=1000,\n",
    "                               depth=6,\n",
    "                               learning_rate=0.1,\n",
    "                               custom_loss=['Accuracy'],\n",
    "                               eval_metric='Accuracy',\n",
    "                               verbose=False,\n",
    "                               use_best_model=True,\n",
    "                               task_type='CPU')\n",
    "\n",
    "    model.fit(train_X, train_y, eval_set=(test_X, test_y),\n",
    "              early_stopping_rounds=50, plot=False)\n",
    "\n",
    "    # train\\test split\n",
    "    train_X, test_X, train_y, test_y = train_test_split(\n",
    "        X_meta, y_meta, train_size=0.5, test_size=0.5, shuffle=True)\n",
    "\n",
    "    # learn meta model with train and validation subsets\n",
    "    meta_model = CatBoostClassifier(iterations=1000,\n",
    "                                    depth=6,\n",
    "                                    learning_rate=0.1,\n",
    "                                    custom_loss=['Accuracy'],\n",
    "                                    eval_metric='Accuracy',\n",
    "                                    verbose=False,\n",
    "                                    use_best_model=True,\n",
    "                                    task_type='CPU')\n",
    "\n",
    "    meta_model.fit(train_X, train_y, eval_set=(test_X, test_y),\n",
    "              early_stopping_rounds=50, plot=False)\n",
    "\n",
    "    # predict on new data (validation plus learning)\n",
    "    pr_tst = get_historic_prices()\n",
    "    pr_tst = get_features(pr_tst)\n",
    "    X = pr_tst[pr_tst.columns[1:]]\n",
    "    X.columns = [''] * len(X.columns)\n",
    "    X_meta = X.copy()\n",
    "\n",
    "    # predict the learned models (base and meta)\n",
    "    p = model.predict_proba(X)\n",
    "    p_meta = meta_model.predict_proba(X_meta)\n",
    "\n",
    "    p2 = [x[0] < 0.5 for x in p]\n",
    "    p2_meta = [x[0] < 0.5 for x in p_meta]\n",
    "    pr2 = pr_tst.iloc[:len(p2)].copy()\n",
    "    pr2['labels'] = p2\n",
    "    pr2['meta_labels'] = p2_meta\n",
    "    pr2['labels'] = pr2['labels'].astype(float)\n",
    "    pr2['meta_labels'] = pr2['meta_labels'].astype(float)\n",
    "    full_pr = pr2.copy()\n",
    "    pr2 = pr2[pr2.index >= TSTART_DATE]\n",
    "    pr2 = pr2[pr2.index <= STOP_DATE]\n",
    "\n",
    "    # add bad samples of this iteratin (bad meta labels)\n",
    "    global BAD_SAMPLES_BOOK\n",
    "    BAD_SAMPLES_BOOK = BAD_SAMPLES_BOOK.append(pr2[pr2['meta_labels']==0.0].index)\n",
    "    \n",
    "    # test models and resample meta labels\n",
    "    R2, meta_labels = tester(pr2, MARKUP, use_meta=True, plot=False)\n",
    "    pr2['meta_labels'] = meta_labels\n",
    "\n",
    "    # resample labels based on meta labels\n",
    "    pr2 = labelling_relabeling(pr2, relabeling=True)\n",
    "    pr2['labels'] = pr2['labels'].astype(float)\n",
    "    pr2['meta_labels'] = pr2['meta_labels'].astype(float)\n",
    "\n",
    "    # mark bad labels from bad_samples_book\n",
    "    if BAD_SAMPLES_BOOK.value_counts().max() > 1:\n",
    "        to_mark = BAD_SAMPLES_BOOK.value_counts()\n",
    "        mean = to_mark.mean()\n",
    "        marked_idx = to_mark[to_mark > mean*bad_samples_fraction].index\n",
    "        pr2.loc[pr2.index.isin(marked_idx), 'meta_labels'] = 0.0\n",
    "    else:\n",
    "        pr2.loc[pr2.index.isin(BAD_SAMPLES_BOOK), 'meta_labels'] = 0.0\n",
    "\n",
    "    R2, _ = tester(full_pr, MARKUP, use_meta=True, plot=False)\n",
    "\n",
    "    return [R2, model, meta_model, pr2]\n",
    "\n",
    "def test_model(result: list):\n",
    "    pr_tst = get_historic_prices()\n",
    "    pr_tst = get_features(pr_tst)\n",
    "    X = get_X(pr_tst)\n",
    "    X_meta = X.copy()\n",
    "\n",
    "    # test the learned model\n",
    "    p = result[1].predict_proba(X)\n",
    "    p_meta = result[2].predict_proba(X_meta)\n",
    "    p2 = [x[0] < 0.5 for x in p]\n",
    "    p2_meta = [x[0] < 0.5 for x in p_meta]\n",
    "    pr2 = pr_tst.iloc[:len(p2)].copy()\n",
    "    pr2['labels'] = p2\n",
    "    pr2['labels'] = pr2['labels'].astype(float)\n",
    "    pr2['meta_labels'] = p2_meta  \n",
    "    pr2['meta_labels'] = pr2['meta_labels'].astype(float)\n",
    "    R2, meta_labels = tester(pr2, MARKUP, use_meta=True, plot=True)\n",
    "\n",
    "def export_model_to_MQL_code(model, model_number):\n",
    "    model[1].save_model('catmodel.h',\n",
    "                     format=\"cpp\",\n",
    "                     export_parameters=None,\n",
    "                     pool=None)\n",
    "    model[2].save_model('meta_catmodel.h',\n",
    "                     format=\"cpp\",\n",
    "                     export_parameters=None,\n",
    "                     pool=None)\n",
    "    # add variables\n",
    "    code = '#include <Math\\Stat\\Math.mqh>'\n",
    "    code += '\\n'\n",
    "    code += 'int MAs' + model_number + '[' + str(len(MA_PERIODS)) + \\\n",
    "        '] = {' + ','.join(map(str, MA_PERIODS)) + '};'\n",
    "    code += '\\n'\n",
    "\n",
    "    # get features\n",
    "    code += 'void fill_arays' + model_number + '( double &features[]) {\\n'\n",
    "    code += '   double pr[], ret[];\\n'\n",
    "    code += '   ArrayResize(ret, 1);\\n'\n",
    "    code += '   for(int i=ArraySize(MAs' + model_number + ')-1; i>=0; i--) {\\n'\n",
    "    code += '       CopyClose(NULL,PERIOD_CURRENT,1,MAs' + model_number + '[i],pr);\\n'\n",
    "    code += '       double mean = MathMean(pr);\\n'\n",
    "    code += '       double std = MathStandardDeviation(pr);\\n'\n",
    "    code += '       ret[0] = pr[MAs' + model_number + '[i]-1] - mean;\\n'\n",
    "    code += '       ArrayInsert(features, ret, ArraySize(features), 0, WHOLE_ARRAY); }\\n'\n",
    "    code += '   ArraySetAsSeries(features, true);\\n'\n",
    "    code += '}\\n\\n'\n",
    "\n",
    "    # add CatBosst base model\n",
    "    code += 'double catboost_model' + model_number + '(const double &features[]) { \\n'\n",
    "    code += '    '\n",
    "    with open('catmodel.h', 'r') as file:\n",
    "        data = file.read()\n",
    "        code += data[data.find(\"unsigned int TreeDepth\")\n",
    "                               :data.find(\"double Scale = 1;\")]\n",
    "    code += '\\n\\n'\n",
    "    code += 'return ' + \\\n",
    "        'ApplyCatboostModel' + model_number + '(features, TreeDepth, TreeSplits , BorderCounts, Borders, LeafValues); } \\n\\n'\n",
    "\n",
    "    # add CatBosst meta model\n",
    "    code += 'double catboost_meta_model' + model_number + '(const double &features[]) { \\n'\n",
    "    code += '    '\n",
    "    with open('meta_catmodel.h', 'r') as file:\n",
    "        data = file.read()\n",
    "        code += data[data.find(\"unsigned int TreeDepth\")\n",
    "                               :data.find(\"double Scale = 1;\")]\n",
    "    code += '\\n\\n'\n",
    "    code += 'return ' + \\\n",
    "        'ApplyCatboostModel' + model_number + '(features, TreeDepth, TreeSplits , BorderCounts, Borders, LeafValues); } \\n\\n'\n",
    "\n",
    "    code += 'double ApplyCatboostModel' + model_number + '(const double &features[],uint &TreeDepth_[],uint &TreeSplits_[],uint &BorderCounts_[],float &Borders_[],double &LeafValues_[]) {\\n\\\n",
    "    uint FloatFeatureCount=ArrayRange(BorderCounts_,0);\\n\\\n",
    "    uint BinaryFeatureCount=ArrayRange(Borders_,0);\\n\\\n",
    "    uint TreeCount=ArrayRange(TreeDepth_,0);\\n\\\n",
    "    bool     binaryFeatures[];\\n\\\n",
    "    ArrayResize(binaryFeatures,BinaryFeatureCount);\\n\\\n",
    "    uint binFeatureIndex=0;\\n\\\n",
    "    for(uint i=0; i<FloatFeatureCount; i++) {\\n\\\n",
    "       for(uint j=0; j<BorderCounts_[i]; j++) {\\n\\\n",
    "          binaryFeatures[binFeatureIndex]=features[i]>Borders_[binFeatureIndex];\\n\\\n",
    "          binFeatureIndex++;\\n\\\n",
    "       }\\n\\\n",
    "    }\\n\\\n",
    "    double result=0.0;\\n\\\n",
    "    uint treeSplitsPtr=0;\\n\\\n",
    "    uint leafValuesForCurrentTreePtr=0;\\n\\\n",
    "    for(uint treeId=0; treeId<TreeCount; treeId++) {\\n\\\n",
    "       uint currentTreeDepth=TreeDepth_[treeId];\\n\\\n",
    "       uint index=0;\\n\\\n",
    "       for(uint depth=0; depth<currentTreeDepth; depth++) {\\n\\\n",
    "          index|=(binaryFeatures[TreeSplits_[treeSplitsPtr+depth]]<<depth);\\n\\\n",
    "       }\\n\\\n",
    "       result+=LeafValues_[leafValuesForCurrentTreePtr+index];\\n\\\n",
    "       treeSplitsPtr+=currentTreeDepth;\\n\\\n",
    "       leafValuesForCurrentTreePtr+=(1<<currentTreeDepth);\\n\\\n",
    "    }\\n\\\n",
    "    return 1.0/(1.0+MathPow(M_E,-result));\\n\\\n",
    "    }\\n\\n'\n",
    "\n",
    "\n",
    "\n",
    "    # file = open('/Users/dmitrievsky/Desktop/py files/mql models/' + str(SYMBOL) + 'cat_model_META_NEW' + model_number + '.mqh', \"w\")\n",
    "    file = open(str(SYMBOL) + 'cat_model_META_NEW' + model_number + '.mqh', \"w\")\n",
    "    file.write(code)\n",
    "\n",
    "    file.close()\n",
    "    print('The file ' + 'cat_model' + '.mqh ' + 'has been written to disc')\n",
    "\n",
    "\n",
    "# make dataset\n",
    "pr = get_historic_prices()\n",
    "pr = get_features(pr)\n",
    "pr = labelling_relabeling(pr, relabeling=False)\n",
    "a, b = tester(pr, MARKUP, use_meta=False, plot=False)\n",
    "pr['meta_labels'] = b\n",
    "pr = pr.dropna()\n",
    "pr = labelling_relabeling(pr, relabeling=True)\n",
    "\n",
    "# iterative learning\n",
    "res = []\n",
    "BAD_SAMPLES_BOOK = pd.DatetimeIndex([])\n",
    "for i in range(25):\n",
    "    res.append(brute_force(pr[pr.columns[1:]], bad_samples_fraction=0.5))\n",
    "\n",
    "    print('Iteration: {}, R^2: {}'.format(i, res[-1][0]))\n",
    "    pr = res[-1][3] \n",
    "\n",
    "# export best model to mql\n",
    "# export_model_to_MQL_code(res[-1], str(1))\n",
    "\n",
    "# test best model\n",
    "res.sort()\n",
    "best_model=res[-1]\n",
    "p = test_model(best_model)\n",
    "\n",
    "# save model\n",
    "best_model[1].save_model(\"catmodel.cbm\")\n",
    "best_model[2].save_model(\"meta_catmodel.cbm\")\n",
    "\n",
    "# export best model to mql\n",
    "# export_model_to_MQL_code(best_model, str(1))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
