{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://www.mql5.com/en/articles/9138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3.9 -m pip install --upgrade pip\n",
    "%pip install --upgrade catboost sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from features\n"
     ]
    }
   ],
   "source": [
    "from cmath import cos\n",
    "import catboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "\n",
    "from pea.features import update_features, get_historic_prices, SYMBOL, get_X\n",
    "\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "MARKUP = 0.00002\n",
    "START_DATE = datetime(2021, 1, 1)\n",
    "TSTART_DATE = datetime(2018, 1, 1)\n",
    "STOP_DATE = datetime(2022, 1, 1)\n",
    "BAD_SAMPLES_BOOK = pd.DatetimeIndex([])\n",
    "\n",
    "def labelling_relabeling(dataset, min=15, max=35, relabeling=False):\n",
    "    labels = []\n",
    "    for i in range(dataset.shape[0]-max):\n",
    "        rand = random.randint(min, max)\n",
    "        curr_pr = dataset['close'][i]\n",
    "        future_pr = dataset['close'][i + rand]\n",
    "\n",
    "        if relabeling:\n",
    "            m_labels  = dataset['meta_labels'][i:rand+1].values\n",
    "        \n",
    "        if relabeling and 0.0 in m_labels:\n",
    "            labels.append(2.0)\n",
    "        else:\n",
    "            if future_pr + MARKUP < curr_pr:\n",
    "                labels.append(1.0)\n",
    "            elif future_pr - MARKUP > curr_pr:\n",
    "                labels.append(0.0)\n",
    "            else:\n",
    "                labels.append(2.0)\n",
    "        \n",
    "    dataset = dataset.iloc[:len(labels)].copy()\n",
    "    dataset['labels'] = labels\n",
    "    dataset = dataset.dropna()\n",
    "    dataset = dataset.drop(\n",
    "        dataset[dataset.labels == 2].index)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def tester(dataset: pd.DataFrame, markup=0.0, use_meta=False, plot=False):\n",
    "    last_deal = int(2)\n",
    "    last_price = 0.0\n",
    "    report = [0.0]\n",
    "    meta_labels = dataset['labels'].copy()\n",
    "\n",
    "    for i in range(dataset.shape[0]):\n",
    "        pred = dataset['labels'][i]\n",
    "        meta_labels[i] = np.nan\n",
    "        if use_meta:\n",
    "            pred_meta = dataset['meta_labels'][i] # 1 = allow trades\n",
    "\n",
    "        if last_deal == 2 and ((use_meta and pred_meta==1) or not use_meta):\n",
    "            last_price = dataset['close'][i]\n",
    "            last_deal = 0 if pred <= 0.5 else 1\n",
    "            continue\n",
    "\n",
    "        if last_deal == 0 and pred > 0.5 and ((use_meta and pred_meta==1) or not use_meta):\n",
    "            last_deal = 2\n",
    "            report.append(report[-1] - markup +\n",
    "                          (dataset['close'][i] - last_price))\n",
    "            if report[-1] > report[-2]:\n",
    "                meta_labels[i] = 1\n",
    "            else:\n",
    "                meta_labels[i] = 0\n",
    "            continue\n",
    "\n",
    "        if last_deal == 1 and pred < 0.5 and ((use_meta and pred_meta==1) or not use_meta):\n",
    "            last_deal = 2\n",
    "            report.append(report[-1] - markup +\n",
    "                          (last_price - dataset['close'][i]))\n",
    "            if report[-1] > report[-2]:\n",
    "                meta_labels[i] = 1\n",
    "            else:\n",
    "                meta_labels[i] = 0\n",
    "\n",
    "    y = np.array(report).reshape(-1, 1)\n",
    "    X = np.arange(len(report)).reshape(-1, 1)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X, y)\n",
    "\n",
    "    l = lr.coef_\n",
    "    if l >= 0:\n",
    "        l = 1\n",
    "    else:\n",
    "        l = -1\n",
    "\n",
    "    if(plot):\n",
    "        plt.plot(report)\n",
    "        plt.plot(lr.predict(X))\n",
    "        plt.title(\"Strategy performance R^2 \" + str(format(lr.score(X, y) * l,\".2f\")))\n",
    "        plt.xlabel(\"the number of trades\")\n",
    "        plt.ylabel(\"cumulative profit in pips\")\n",
    "        plt.show()\n",
    "\n",
    "    return lr.score(X, y) * l, meta_labels.fillna(method='backfill')\n",
    "\n",
    "def brute_force(dataset, bad_samples_fraction=0.5):\n",
    "    # features for model\\meta models. We learn main model only on filtered labels \n",
    "    X = dataset[dataset['meta_labels']==1]\n",
    "    X = dataset[dataset.columns[:-2]]\n",
    "    X = X[X.index >= START_DATE]\n",
    "    X = X[X.index <= STOP_DATE]\n",
    "\n",
    "    X_meta = dataset[dataset.columns[:-2]]\n",
    "    X_meta = X_meta[X_meta.index >= TSTART_DATE]\n",
    "    X_meta = X_meta[X_meta.index <= STOP_DATE]\n",
    "\n",
    "    # labels for model\\meta models\n",
    "    y = dataset[dataset['meta_labels']==1]\n",
    "    y = dataset[dataset.columns[-2]]\n",
    "    y = y[y.index >= START_DATE]\n",
    "    y = y[y.index <= STOP_DATE]\n",
    "\n",
    "    y_meta = dataset[dataset.columns[-1]]\n",
    "    y_meta = y_meta[y_meta.index >= TSTART_DATE]\n",
    "    y_meta = y_meta[y_meta.index <= STOP_DATE]\n",
    "\n",
    "    # train\\test split\n",
    "    train_X, test_X, train_y, test_y = train_test_split(\n",
    "        X, y, train_size=0.5, test_size=0.5, shuffle=True)\n",
    "\n",
    "    # learn main model with train and validation subsets\n",
    "    model = CatBoostClassifier(iterations=1000,\n",
    "                               depth=6,\n",
    "                               learning_rate=0.1,\n",
    "                               custom_loss=['Accuracy'],\n",
    "                               eval_metric='Accuracy',\n",
    "                               verbose=False,\n",
    "                               use_best_model=True,\n",
    "                               task_type='CPU')\n",
    "\n",
    "    model.fit(train_X, train_y, eval_set=(test_X, test_y),\n",
    "              early_stopping_rounds=50, plot=False)\n",
    "\n",
    "    # train\\test split\n",
    "    train_X, test_X, train_y, test_y = train_test_split(\n",
    "        X_meta, y_meta, train_size=0.5, test_size=0.5, shuffle=True)\n",
    "\n",
    "    # learn meta model with train and validation subsets\n",
    "    meta_model = CatBoostClassifier(iterations=1000,\n",
    "                                    depth=6,\n",
    "                                    learning_rate=0.1,\n",
    "                                    custom_loss=['Accuracy'],\n",
    "                                    eval_metric='Accuracy',\n",
    "                                    verbose=False,\n",
    "                                    use_best_model=True,\n",
    "                                    task_type='CPU')\n",
    "\n",
    "    meta_model.fit(train_X, train_y, eval_set=(test_X, test_y),\n",
    "              early_stopping_rounds=50, plot=False)\n",
    "\n",
    "    # predict on new data (validation plus learning)\n",
    "    pr_tst = get_historic_prices()\n",
    "    X = pr_tst[pr_tst.columns[1:]]\n",
    "    X.columns = [''] * len(X.columns)\n",
    "    X_meta = X.copy()\n",
    "\n",
    "    # predict the learned models (base and meta)\n",
    "    p = model.predict_proba(X)\n",
    "    p_meta = meta_model.predict_proba(X_meta)\n",
    "\n",
    "    p2 = [x[0] < 0.5 for x in p]\n",
    "    p2_meta = [x[0] < 0.5 for x in p_meta]\n",
    "    pr2 = pr_tst.iloc[:len(p2)].copy()\n",
    "    pr2['labels'] = p2\n",
    "    pr2['meta_labels'] = p2_meta\n",
    "    pr2['labels'] = pr2['labels'].astype(float)\n",
    "    pr2['meta_labels'] = pr2['meta_labels'].astype(float)\n",
    "    full_pr = pr2.copy()\n",
    "    pr2 = pr2[pr2.index >= TSTART_DATE]\n",
    "    pr2 = pr2[pr2.index <= STOP_DATE]\n",
    "\n",
    "    # add bad samples of this iteratin (bad meta labels)\n",
    "    global BAD_SAMPLES_BOOK\n",
    "    BAD_SAMPLES_BOOK = BAD_SAMPLES_BOOK.append(pr2[pr2['meta_labels']==0.0].index)\n",
    "    \n",
    "    # test models and resample meta labels\n",
    "    R2, meta_labels = tester(pr2, MARKUP, use_meta=True, plot=False)\n",
    "    pr2['meta_labels'] = meta_labels\n",
    "\n",
    "    # resample labels based on meta labels\n",
    "    pr2 = labelling_relabeling(pr2, relabeling=True)\n",
    "    pr2['labels'] = pr2['labels'].astype(float)\n",
    "    pr2['meta_labels'] = pr2['meta_labels'].astype(float)\n",
    "\n",
    "    # mark bad labels from bad_samples_book\n",
    "    if BAD_SAMPLES_BOOK.value_counts().max() > 1:\n",
    "        to_mark = BAD_SAMPLES_BOOK.value_counts()\n",
    "        mean = to_mark.mean()\n",
    "        marked_idx = to_mark[to_mark > mean*bad_samples_fraction].index\n",
    "        pr2.loc[pr2.index.isin(marked_idx), 'meta_labels'] = 0.0\n",
    "    else:\n",
    "        pr2.loc[pr2.index.isin(BAD_SAMPLES_BOOK), 'meta_labels'] = 0.0\n",
    "\n",
    "    R2, _ = tester(full_pr, MARKUP, use_meta=True, plot=False)\n",
    "\n",
    "    return [R2, model, meta_model, pr2]\n",
    "\n",
    "def test_model(result: list):\n",
    "    pr_tst = get_historic_prices()\n",
    "    # print('pr_tst')\n",
    "    # print(pr_tst)\n",
    "    # print(pr_tst.describe())\n",
    "    X = get_X(pr_tst)\n",
    "    # print('X')\n",
    "    # print(X)\n",
    "    # print(X.describe())\n",
    "    # X.columns = [''] * len(X.columns)\n",
    "    X_meta = X.copy()\n",
    "    # print('X_meta')\n",
    "    # print(X_meta)\n",
    "    # print(X_meta.describe())\n",
    "\n",
    "    # test the learned model\n",
    "    p = result[1].predict_proba(X)\n",
    "    p_meta = result[2].predict_proba(X_meta)\n",
    "    p2 = [x[0] < 0.5 for x in p]\n",
    "    p2_meta = [x[0] < 0.5 for x in p_meta]\n",
    "    pr2 = pr_tst.iloc[:len(p2)].copy()\n",
    "    pr2['labels'] = p2\n",
    "    pr2['labels'] = pr2['labels'].astype(float)\n",
    "    pr2['meta_labels'] = p2_meta  \n",
    "    pr2['meta_labels'] = pr2['meta_labels'].astype(float)\n",
    "    R2, meta_labels = tester(pr2, MARKUP, use_meta=True, plot=True)\n",
    "\n",
    "def export_model_to_MQL_code(model, model_number):\n",
    "    model[1].save_model('catmodel.h',\n",
    "                     format=\"cpp\",\n",
    "                     export_parameters=None,\n",
    "                     pool=None)\n",
    "    model[2].save_model('meta_catmodel.h',\n",
    "                     format=\"cpp\",\n",
    "                     export_parameters=None,\n",
    "                     pool=None)\n",
    "    # add variables\n",
    "    code = '#include <Math\\Stat\\Math.mqh>'\n",
    "    code += '\\n'\n",
    "    code += 'int MAs' + model_number + '[' + str(len(MA_PERIODS)) + \\\n",
    "        '] = {' + ','.join(map(str, MA_PERIODS)) + '};'\n",
    "    code += '\\n'\n",
    "\n",
    "    # get features\n",
    "    code += 'void fill_arays' + model_number + '( double &features[]) {\\n'\n",
    "    code += '   double pr[], ret[];\\n'\n",
    "    code += '   ArrayResize(ret, 1);\\n'\n",
    "    code += '   for(int i=ArraySize(MAs' + model_number + ')-1; i>=0; i--) {\\n'\n",
    "    code += '       CopyClose(NULL,PERIOD_CURRENT,1,MAs' + model_number + '[i],pr);\\n'\n",
    "    code += '       double mean = MathMean(pr);\\n'\n",
    "    code += '       double std = MathStandardDeviation(pr);\\n'\n",
    "    code += '       ret[0] = pr[MAs' + model_number + '[i]-1] - mean;\\n'\n",
    "    code += '       ArrayInsert(features, ret, ArraySize(features), 0, WHOLE_ARRAY); }\\n'\n",
    "    code += '   ArraySetAsSeries(features, true);\\n'\n",
    "    code += '}\\n\\n'\n",
    "\n",
    "    # add CatBosst base model\n",
    "    code += 'double catboost_model' + model_number + '(const double &features[]) { \\n'\n",
    "    code += '    '\n",
    "    with open('catmodel.h', 'r') as file:\n",
    "        data = file.read()\n",
    "        code += data[data.find(\"unsigned int TreeDepth\")\n",
    "                               :data.find(\"double Scale = 1;\")]\n",
    "    code += '\\n\\n'\n",
    "    code += 'return ' + \\\n",
    "        'ApplyCatboostModel' + model_number + '(features, TreeDepth, TreeSplits , BorderCounts, Borders, LeafValues); } \\n\\n'\n",
    "\n",
    "    # add CatBosst meta model\n",
    "    code += 'double catboost_meta_model' + model_number + '(const double &features[]) { \\n'\n",
    "    code += '    '\n",
    "    with open('meta_catmodel.h', 'r') as file:\n",
    "        data = file.read()\n",
    "        code += data[data.find(\"unsigned int TreeDepth\")\n",
    "                               :data.find(\"double Scale = 1;\")]\n",
    "    code += '\\n\\n'\n",
    "    code += 'return ' + \\\n",
    "        'ApplyCatboostModel' + model_number + '(features, TreeDepth, TreeSplits , BorderCounts, Borders, LeafValues); } \\n\\n'\n",
    "\n",
    "    code += 'double ApplyCatboostModel' + model_number + '(const double &features[],uint &TreeDepth_[],uint &TreeSplits_[],uint &BorderCounts_[],float &Borders_[],double &LeafValues_[]) {\\n\\\n",
    "    uint FloatFeatureCount=ArrayRange(BorderCounts_,0);\\n\\\n",
    "    uint BinaryFeatureCount=ArrayRange(Borders_,0);\\n\\\n",
    "    uint TreeCount=ArrayRange(TreeDepth_,0);\\n\\\n",
    "    bool     binaryFeatures[];\\n\\\n",
    "    ArrayResize(binaryFeatures,BinaryFeatureCount);\\n\\\n",
    "    uint binFeatureIndex=0;\\n\\\n",
    "    for(uint i=0; i<FloatFeatureCount; i++) {\\n\\\n",
    "       for(uint j=0; j<BorderCounts_[i]; j++) {\\n\\\n",
    "          binaryFeatures[binFeatureIndex]=features[i]>Borders_[binFeatureIndex];\\n\\\n",
    "          binFeatureIndex++;\\n\\\n",
    "       }\\n\\\n",
    "    }\\n\\\n",
    "    double result=0.0;\\n\\\n",
    "    uint treeSplitsPtr=0;\\n\\\n",
    "    uint leafValuesForCurrentTreePtr=0;\\n\\\n",
    "    for(uint treeId=0; treeId<TreeCount; treeId++) {\\n\\\n",
    "       uint currentTreeDepth=TreeDepth_[treeId];\\n\\\n",
    "       uint index=0;\\n\\\n",
    "       for(uint depth=0; depth<currentTreeDepth; depth++) {\\n\\\n",
    "          index|=(binaryFeatures[TreeSplits_[treeSplitsPtr+depth]]<<depth);\\n\\\n",
    "       }\\n\\\n",
    "       result+=LeafValues_[leafValuesForCurrentTreePtr+index];\\n\\\n",
    "       treeSplitsPtr+=currentTreeDepth;\\n\\\n",
    "       leafValuesForCurrentTreePtr+=(1<<currentTreeDepth);\\n\\\n",
    "    }\\n\\\n",
    "    return 1.0/(1.0+MathPow(M_E,-result));\\n\\\n",
    "    }\\n\\n'\n",
    "\n",
    "\n",
    "\n",
    "    # file = open('/Users/dmitrievsky/Desktop/py files/mql models/' + str(SYMBOL) + 'cat_model_META_NEW' + model_number + '.mqh', \"w\")\n",
    "    file = open(str(SYMBOL) + 'cat_model_META_NEW' + model_number + '.mqh', \"w\")\n",
    "    file.write(code)\n",
    "\n",
    "    file.close()\n",
    "    print('The file ' + 'cat_model' + '.mqh ' + 'has been written to disc')\n",
    "\n",
    "\n",
    "# make dataset\n",
    "pr = get_historic_prices()\n",
    "pr = labelling_relabeling(pr, relabeling=False)\n",
    "a, b = tester(pr, MARKUP, use_meta=False, plot=False)\n",
    "pr['meta_labels'] = b\n",
    "pr = pr.dropna()\n",
    "pr = labelling_relabeling(pr, relabeling=True)\n",
    "\n",
    "# iterative learning\n",
    "res = []\n",
    "BAD_SAMPLES_BOOK = pd.DatetimeIndex([])\n",
    "for i in range(25):\n",
    "    res.append(brute_force(pr[pr.columns[1:]], bad_samples_fraction=0.5))\n",
    "\n",
    "    print('Iteration: {}, R^2: {}'.format(i, res[-1][0]))\n",
    "    pr = res[-1][3] \n",
    "\n",
    "# export best model to mql\n",
    "# export_model_to_MQL_code(res[-1], str(1))\n",
    "\n",
    "# test best model\n",
    "res.sort()\n",
    "best_model=res[-1]\n",
    "p = test_model(best_model)\n",
    "\n",
    "# save model\n",
    "best_model[1].save_model(\"catmodel.cbm\")\n",
    "best_model[2].save_model(\"meta_catmodel.cbm\")\n",
    "\n",
    "# export best model to mql\n",
    "# export_model_to_MQL_code(best_model, str(1))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
